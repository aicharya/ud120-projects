{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parse_out_email_text.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aicharya/ud120-projects/blob/master/tools/parse_out_email_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPCZgSvaC-ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "54ee5728-a1b1-482a-9619-1795b00e6d9e"
      },
      "source": [
        "!git clone https://github.com/aicharya/ud120-projects.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ud120-projects'...\n",
            "remote: Enumerating objects: 113, done.\u001b[K\n",
            "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 5298 (delta 70), reused 0 (delta 0), pack-reused 5185\u001b[K\n",
            "Receiving objects: 100% (5298/5298), 19.94 MiB | 20.07 MiB/s, done.\n",
            "Resolving deltas: 100% (4521/4521), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9cR2VjWFzq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "56242230-c75a-4428-ef88-88ab4525596b"
      },
      "source": [
        "import os\n",
        "os.chdir('ud120-projects/tools')\n",
        "os.listdir(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['python2_lesson06_keys.pkl',\n",
              " 'parse_out_email_text.ipynb',\n",
              " 'python2_lesson13_keys.pkl',\n",
              " 'feature_format.py',\n",
              " 'parse_out_email_text.py',\n",
              " 'email_authors.pkl',\n",
              " 'startup.py',\n",
              " 'python2_lesson14_keys.pkl',\n",
              " 'word_data.pkl',\n",
              " 'email_preprocess.py']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87n0JDBfGAY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvkpjP21GJWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parseOutText(f):\n",
        "    \"\"\" given an opened email file f, parse out all text below the\n",
        "        metadata block at the top\n",
        "        (in Part 2, you will also add stemming capabilities)\n",
        "        and return a string that contains all the words\n",
        "        in the email (space-separated) \n",
        "        \n",
        "        example use case:\n",
        "        f = open(\"email_file_name.txt\", \"r\")\n",
        "        text = parseOutText(f)\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    f.seek(0)  ### go back to beginning of file (annoying)\n",
        "    all_text = f.read()\n",
        "\n",
        "    ### split off metadata\n",
        "    content = all_text.split(\"X-FileName:\")\n",
        "    words = \"\"\n",
        "    if len(content) > 1:\n",
        "        ### remove punctuation\n",
        "        text_string = content[1].translate(string.maketrans(\"\", \"\"), string.punctuation)\n",
        "        \n",
        "        stemmer = stemmer = SnowballStemmer(\"english\")\n",
        "        ### project part 2: comment out the line below\n",
        "        #words = text_string\n",
        "        \n",
        "        ### split the text string into individual words, stem each word,\n",
        "        ### and append the stemmed word to words (make sure there's a single\n",
        "        ### space between each stemmed word)\n",
        "        stem_words = [stemmer.stem(word) for word in text_string.split()]\n",
        "        words = ' '.join(stem_words)\n",
        "\n",
        "    return words\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoiCNzTlGY7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1428e45e-639c-4490-fe67-f4ee1b3e0a93"
      },
      "source": [
        "def main():\n",
        "    ff = open(\"../text_learning/test_email.txt\", \"r\")\n",
        "    text = parseOutText(ff)\n",
        "    print text\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi everyon if you can read this messag your proper use parseouttext pleas proceed to the next part of the project\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}